{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## _Computer Vision_\n",
    "### Lab 5, _Image Interpolation_.\n",
    "#### >> Topics  :\n",
    "* ##### Interpolation Methods\n",
    "* ##### Inpainting\n",
    "* ##### Image Pyramids\n",
    "* ##### Edges vs Contours\n",
    "* ##### Hough Space\n",
    "* ##### Hough Circles Detector\n",
    "\n",
    "##### >> Note  :\n",
    "> ##### to close image windows smoothly please **press Esc** on your keyboard, **don't close** it directly by clicking on 'X' to avoid kernel interruption.\n",
    "> - ##### To run this lab using google colab follow below instructions:\n",
    "> 1. Import `cv2_imshow` method using `from google.colab.patches import cv2_imshow`.\n",
    "> 2. Replace all `cv.imshow()` with `cv2_imshow()` with one parameter **name of that image**.\n",
    "> 3. Specify your path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Section 0, _Helper Functions_:\n",
    "> ##### This cell contains some helper function such as error_handler, please run it without any modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# please don't modify this code.\n",
    "def show_text_window(titles):\n",
    "    black = np.zeros((len(titles) * 150, 400))\n",
    "    for idx, t in enumerate(titles):\n",
    "        place = idx + 1\n",
    "        cv.putText(black, t, (10, place * 100),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.75, (200, 0, 200), 1, 2)\n",
    "    cv.imshow(\"Values\", black)\n",
    "\n",
    "\n",
    "def get_updated_value(key, value, **kwargs):\n",
    "    if key == ord('+'):\n",
    "        return value, 0, 0\n",
    "    elif key == ord('-'):\n",
    "        return -value, 0, 0\n",
    "    elif key == ord('*'):\n",
    "        return 0, kwargs.get('value2', value), 0\n",
    "    elif key == ord('/'):\n",
    "        return 0, -kwargs.get('value2', value), 0\n",
    "    elif key == ord('8'):\n",
    "        return 0, 0, kwargs.get('value3', value)\n",
    "    elif key == ord('2'):\n",
    "        return 0, 0, -kwargs.get('value3', value)\n",
    "    elif key == 27:\n",
    "        raise Exception('Terminated by user!')\n",
    "    else:\n",
    "        return 0, 0, 0\n",
    "\n",
    "\n",
    "def error_handler(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as ex:\n",
    "            cv.destroyAllWindows()\n",
    "            print(f'{ex}')\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Section 1, _Interpolation Methods_:\n",
    "* ##### Interpolation methods are used to estimate pixel values at non-integer coordinates when resizing images.\n",
    "* ##### The choice of interpolation method affects the quality of the resized image.\n",
    "* ##### [Click to check the documentation](https://docs.opencv.org/3.4/da/d54/group__imgproc__transform.html)\n",
    "![image info](https://upload.wikimedia.org/wikipedia/commons/thumb/9/90/Comparison_of_1D_and_2D_interpolation.svg/768px-Comparison_of_1D_and_2D_interpolation.svg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminated by user!\n"
     ]
    }
   ],
   "source": [
    "@error_handler\n",
    "def apply_resize_with_interpolation(path):\n",
    "    img = cv.imread(path)\n",
    "    cv.imshow(\"Image\", img)\n",
    "    dimensions = img.shape\n",
    "\n",
    "    interpolation_types = [cv.INTER_NEAREST, cv.INTER_LINEAR, cv.INTER_CUBIC]\n",
    "    interpolation_names = [\n",
    "        \"Nearest Interpolation\", \"Linear Interpolation\", \"Cubic Interpolation\",\n",
    "    ]\n",
    "\n",
    "    scale_ratio = 1\n",
    "    while True:\n",
    "        for interpolation_type, interpolation_name in zip(\n",
    "            interpolation_types, interpolation_names\n",
    "        ):\n",
    "            # resize with interpolation\n",
    "            interpolated = cv.resize(\n",
    "                img,\n",
    "                (int(dimensions[1] * scale_ratio), int(dimensions[0] * scale_ratio)),\n",
    "                interpolation=interpolation_type,\n",
    "            )\n",
    "            cv.imshow(interpolation_name, interpolated)\n",
    "\n",
    "        show_text_window([f\"Scale: {scale_ratio:.1f}\"])\n",
    "\n",
    "        k = cv.waitKey(0)\n",
    "        ds, _, _ = get_updated_value(k, 0.1)\n",
    "        scale_ratio += ds\n",
    "        scale_ratio = max(scale_ratio, 0.1)\n",
    "\n",
    "\n",
    "path = \"../Images/Lenna.png\"\n",
    "apply_resize_with_interpolation(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminated by user!\n"
     ]
    }
   ],
   "source": [
    "path = \"../Images/nature.jpg\"\n",
    "apply_resize_with_interpolation(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Section 2, _Inpainting_:\n",
    "* ##### It's Used in image processing and computer vision to fill in-missing or damaged parts of an image with plausible content.\n",
    "* ##### The goal of inpainting is to restore or complete an image by estimating the missing information based on the surrounding image context\n",
    "* ##### Several algorithms were designed for this purpose and OpenCV provides two of them.\n",
    "* ##### cv.INPAINT_TELEA Algorithm: starts from the boundary of the region and goes inside the region gradually filling everything in the boundary first. It takes a small neighbourhood around the pixel on the neighbourhood to be inpainted. This pixel is replaced by normalized weighted sum of all the known pixels in the neighbourhood.\n",
    "\n",
    "\n",
    "* ##### [Click to check the documentation](https://docs.opencv.org/3.4/df/d3d/tutorial_py_inpainting.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminated by user!\n"
     ]
    }
   ],
   "source": [
    "@error_handler\n",
    "def inpainting(img_path, mask_path):\n",
    "    image = cv.imread(img_path)\n",
    "    mask = cv.imread(mask_path, 0)\n",
    "\n",
    "    # make sure that the dimensions are equal.\n",
    "    assert image.shape[:2] == mask.shape[:2]\n",
    "\n",
    "    # Radius of a circular neighborhood of each point inpainted that is considered by the algorithm.\n",
    "    inpaint_radius = 1\n",
    "    while True:\n",
    "        inpainted_img = cv.inpaint(image, mask, inpaint_radius, cv.INPAINT_TELEA)\n",
    "\n",
    "        cv.imshow(\"OriginalImage\", image)\n",
    "        cv.imshow('mask', mask)\n",
    "        cv.imshow('Result', inpainted_img)\n",
    "\n",
    "        show_text_window([f'Radius: {inpaint_radius}'])\n",
    "\n",
    "        k = cv.waitKey(0)\n",
    "        dr, _, _ = get_updated_value(k, 1)\n",
    "        inpaint_radius += dr\n",
    "\n",
    "\n",
    "img_path = \"../Images/messi.jpg\"\n",
    "mask_path = \"../Images/mask.png\"\n",
    "\n",
    "inpainting(img_path, mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminated by user!\n"
     ]
    }
   ],
   "source": [
    "img_path = \"../Images/messi 2.png\"\n",
    "mask_path = \"../Images/mask 2.png\"\n",
    "\n",
    "inpainting(img_path, mask_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Section 3, _Image Pyramids_:\n",
    "* ##### They are a multi-scale representation of an image at different resolutions.\n",
    "* ##### They are constructed by repeatedly applying a smoothing and down-sampling operation to the original image to generate a series of images at different scales.\n",
    "\n",
    "* ##### cv.pyrDown: it performs the downsampling step of the Gaussian pyramid construction. First, it convolves the source image with 5x5 Gaussian kernel and then it downsamples the image by rejecting even rows and columns.\n",
    "\n",
    "\n",
    "* ##### cv.pyrUp: it performs the upsampling step of the Gaussian pyramid construction. First, it upsamples the source image by injecting even zero rows and columns and then convolves the result with the same kernel as in pyrDown multiplied by 4.\n",
    "\n",
    "* ##### [Click to check the documentation](https://docs.opencv.org/3.4/d4/d1f/tutorial_pyramids.html)\n",
    "![image info](https://upload.wikimedia.org/wikipedia/commons/thumb/4/43/Image_pyramid.svg/800px-Image_pyramid.svg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@error_handler\n",
    "def pyramid(path):\n",
    "    img = cv.imread(path)\n",
    "    lower_res = cv.pyrDown(img)\n",
    "    upper_res = cv.pyrUp(img)\n",
    "    show_text_window([f'Image Dimensions: {img.shape[:2]}', f'Lower Dimensions: {lower_res.shape[:2]}',\n",
    "                      f'Upper Dimensions: {upper_res.shape[:2]}'])\n",
    "\n",
    "    cv.imshow('Original Image', img)\n",
    "    cv.imshow('Lower Resolution', lower_res)\n",
    "    cv.imshow('Upper Resolution', upper_res)\n",
    "\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "path = \"../Images/home.jpg\"\n",
    "pyramid(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Section 4, _Edges vs Contours_:\n",
    "* ##### Contours are used to identify and represent the boundaries or outlines of objects in an image.\n",
    "* ##### They provide information about the shapes and spatial relationships of objects within the image.\n",
    "* ##### The output of contour detection is a set of curves that represent the boundaries of objects or regions in the image.\n",
    "* ##### [Click to check the documentation](https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminated by user!\n"
     ]
    }
   ],
   "source": [
    "@error_handler\n",
    "def contours(path):\n",
    "    image = cv.imread(path)\n",
    "    image = cv.resize(image, (image.shape[1] // 2, image.shape[0] // 2))\n",
    "    gray = cv.cvtColor(image, cv.COLOR_RGB2GRAY)\n",
    "\n",
    "    thresh = 100\n",
    "    while True:\n",
    "        image_copy = image.copy()\n",
    "        _, binary = cv.threshold(gray, thresh, 255, cv.THRESH_BINARY)\n",
    "        cv.imshow(\"Gray Image\", gray)\n",
    "        cv.imshow(\"Binary Image\", binary)\n",
    "\n",
    "        contours, _ = cv.findContours(binary, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "        image_copy = cv.drawContours(image_copy, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "        cv.imshow(\"Input Image\", image)\n",
    "        cv.imshow(\"Contour Detected Image\", image_copy)\n",
    "\n",
    "        show_text_window([f\"Threshold: {thresh}\"])\n",
    "\n",
    "        k = cv.waitKey(0)\n",
    "        dt, _, _ = get_updated_value(k, 10)\n",
    "        thresh += dt\n",
    "\n",
    "\n",
    "path = \"../Images/sudoku.jpg\"\n",
    "contours(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminated by user!\n"
     ]
    }
   ],
   "source": [
    "path = \"../Images/bird.png\"\n",
    "contours(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Section 5, _Hough Space_:\n",
    "* ##### It's a mathematical concept to detect and represent geometric shapes, patterns, and features in an image.\n",
    "* ##### Hough Transform, a technique originally developed for line detection but later extended to detect other shapes such as circles and ellipses.\n",
    "* ##### Hough space plays a crucial role in finding and representing these shapes in a parametric form.\n",
    "* ##### [Click to check the documentation for hough lines.](https://docs.opencv.org/3.4/d9/db0/tutorial_hough_lines.html)\n",
    "![image info](https://miro.medium.com/v2/resize:fit:1400/0*KoAmeuoTu9Uz0eNW.png)\n",
    "* ##### [Click to check the documentation for hough circles.](https://docs.opencv.org/3.4/d4/d70/tutorial_hough_circle.html)\n",
    "![image info](https://www.cis.rit.edu/class/simg782.old/talkHough/circles1.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminated by user!\n"
     ]
    }
   ],
   "source": [
    "@error_handler\n",
    "def circles(path):\n",
    "    image = cv.imread(path)\n",
    "    image = cv.medianBlur(image, 5)\n",
    "    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    minRadius, maxRadius, minDist = 0, 0, 20 \n",
    "    while True:\n",
    "        image_copy = image.copy()\n",
    "        circles = cv.HoughCircles(gray, cv.HOUGH_GRADIENT, dp=1, minDist=minDist, param1=100, param2=25, minRadius=minRadius, maxRadius=maxRadius)\n",
    "        \n",
    "        if circles is not None:\n",
    "            circles = np.uint16(np.around(circles))\n",
    "\n",
    "            for circle in circles[0]:\n",
    "                *center, radius = circle\n",
    "                cv.circle(image_copy, center, radius, (0, 255, 0), 2)\n",
    "                cv.circle(image_copy, center, 2, (0, 0, 255), 3)\n",
    "\n",
    "        cv.imshow('Detected Circles', image_copy)\n",
    "\n",
    "        show_text_window([\n",
    "            f\"Min Radius: {minRadius}\", f\"Max Radius: {maxRadius}\", f\"Min Distance: {minDist}\",\n",
    "            ])\n",
    "\n",
    "        k = cv.waitKey(0)\n",
    "        dmn, dmx, dds = get_updated_value(k, 10, value3=1)\n",
    "        minRadius += dmn\n",
    "        maxRadius += dmx\n",
    "        minDist += dds\n",
    "\n",
    "path = \"../Images/coins.jpg\"\n",
    "circles(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## _The End_."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
