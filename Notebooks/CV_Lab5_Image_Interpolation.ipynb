{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## _Computer Vision_\n",
    "### Lab 5, _Image Interpolation_.\n",
    "#### >> Topics  :\n",
    "* ##### Interpolation Methods\n",
    "* ##### Inpainting\n",
    "* ##### Image Pyramids\n",
    "* ##### Edges vs Contours\n",
    "* ##### Hough Space\n",
    "* ##### Hough Circles Detector\n",
    "\n",
    "##### >> Note  :\n",
    "> ##### to close image windows smoothly please **press Esc** on your keyboard, **don't close** it directly by clicking on 'X' to avoid kernel interruption."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 0, _Helper Functions_:\n",
    "> ##### This cell contains some helper function such as error_handler, please run it without any modification."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# please don't modify this code.\n",
    "def show_text_window(titles):\n",
    "    black = np.zeros((len(titles) * 150, 400))\n",
    "    for idx, t in enumerate(titles):\n",
    "        place = idx + 1\n",
    "        cv.putText(black, t, (10, place * 100),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.75, (200, 0, 200), 1, 2)\n",
    "    cv.imshow(\"Values\", black)\n",
    "\n",
    "\n",
    "def get_updated_value(key, value, **kwargs):\n",
    "    if key == ord('+'):\n",
    "        return value, 0\n",
    "    elif key == ord('-'):\n",
    "        return -value, 0\n",
    "    elif key == ord('*'):\n",
    "        return 0, kwargs.get('value2', value)\n",
    "    elif key == ord('/'):\n",
    "        return 0, -kwargs.get('value2', value)\n",
    "    elif key == 27:\n",
    "        raise Exception('Terminated by user!')\n",
    "    else:\n",
    "        return 0, 0\n",
    "\n",
    "\n",
    "def error_handler(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            func(*args, **kwargs)\n",
    "        except Exception as ex:\n",
    "            cv.destroyAllWindows()\n",
    "            print(f'{ex}')\n",
    "\n",
    "    return wrapper"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 1, _Interpolation Methods_:\n",
    "* ##### Interpolation methods are used to estimate pixel values at non-integer coordinates when resizing images.\n",
    "* ##### The choice of interpolation method affects the quality of the resized image.\n",
    "* ##### [Click to check the documentation](https://docs.opencv.org/3.4/da/d54/group__imgproc__transform.html)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminated by user!\n"
     ]
    }
   ],
   "source": [
    "@error_handler\n",
    "def apply_resize_with_interpolation(path, type='linear'):\n",
    "    img = cv.imread(path)\n",
    "    cv.imshow('Image', img)\n",
    "\n",
    "    scale_ratio = 1\n",
    "    accum = 0\n",
    "    while True:\n",
    "        dimentions = img.shape\n",
    "        if type == 'nearest':\n",
    "            interpolation_tp = cv.INTER_NEAREST\n",
    "        elif type == 'cubic':\n",
    "            interpolation_tp = cv.INTER_CUBIC\n",
    "        else:\n",
    "            interpolation_tp = cv.INTER_LINEAR\n",
    "\n",
    "        # resize with interpolation\n",
    "        interpolated = cv.resize(img, (int(dimentions[1] * scale_ratio), int(dimentions[0] * scale_ratio)),\n",
    "                                 interpolation=interpolation_tp)\n",
    "        cv.imshow(f'{type} Interpolation', interpolated)\n",
    "\n",
    "        # show text\n",
    "        show_text_window([f'Scale: {scale_ratio}'])\n",
    "\n",
    "        # process input.\n",
    "        k = cv.waitKey(0)\n",
    "        uv, _ = get_updated_value(k, 2)\n",
    "        accum += uv\n",
    "        if accum < 0:\n",
    "            scale_ratio = 1 / abs(accum)\n",
    "        elif accum == 0:\n",
    "            continue\n",
    "        else:\n",
    "            scale_ratio = accum\n",
    "\n",
    "\n",
    "path = '../Images/Lenna.jpg'\n",
    "apply_resize_with_interpolation(path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 2, _Inpainting_:\n",
    "* ##### It's Used in image processing and computer vision to fill in-missing or damaged parts of an image with plausible content.\n",
    "* ##### The goal of inpainting is to restore or complete an image by estimating the missing information based on the surrounding image context\n",
    "* ##### [Click to check the documentation](https://docs.opencv.org/3.4/df/d3d/tutorial_py_inpainting.html)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminated by user!\n"
     ]
    }
   ],
   "source": [
    "@error_handler\n",
    "def inpainting(img_path, mask_path):\n",
    "    image = cv.imread(img_path)\n",
    "    mask = cv.imread(mask_path, 0)\n",
    "\n",
    "    # make sure that the dimensions are equal.\n",
    "    assert (image.shape[0], image.shape[1]) == mask.shape\n",
    "\n",
    "    # Radius of a circular neighborhood of each point inpainted that is considered by the algorithm.\n",
    "    inpaint_radius = 1\n",
    "    while True:\n",
    "        inpainted_img = cv.inpaint(image, mask, inpaint_radius, cv.INPAINT_TELEA)\n",
    "\n",
    "        cv.imshow(\"OriginalImage\", image)\n",
    "        cv.imshow('mask', mask)\n",
    "        cv.imshow('Result', inpainted_img)\n",
    "\n",
    "        # show text\n",
    "        show_text_window([f'Radius: {inpaint_radius}'])\n",
    "\n",
    "        # process input.\n",
    "        k = cv.waitKey(0)\n",
    "        uv, _ = get_updated_value(k, 1)\n",
    "\n",
    "        # increase / decrease\n",
    "        inpaint_radius += uv\n",
    "\n",
    "\n",
    "img_path = \"../Images/messi.jpg\"\n",
    "mask_path = \"../Images/mask.png\"\n",
    "\n",
    "inpainting(img_path, mask_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 3, _Image Pyramids_:\n",
    "* ##### They are a multi-scale representation of an image at different resolutions.\n",
    "* ##### They are constructed by repeatedly applying a smoothing and down-sampling operation to the original image to generate a series of images at different scales.\n",
    "* ##### [Click to check the documentation](https://docs.opencv.org/3.4/d4/d1f/tutorial_pyramids.htmll)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "@error_handler\n",
    "def pyramid(path):\n",
    "    img = cv.imread(path)\n",
    "    lower_reso = cv.pyrDown(img)\n",
    "    upper_reso = cv.pyrUp(img)\n",
    "    show_text_window([f'Image Dimensions: {img.shape}', f'Lower Dimensions: {lower_reso.shape}',\n",
    "                      f'Upper Dimensions: {upper_reso.shape}'])\n",
    "\n",
    "    cv.imshow('Original Image', img)\n",
    "    cv.imshow('Lower', lower_reso)\n",
    "    cv.imshow('Upper', upper_reso)\n",
    "\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "path = \"../Images/home.jpg\"\n",
    "pyramid(path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 4, _Edges vs Contours_:\n",
    "* ##### Contours are used to identify and represent the boundaries or outlines of objects in an image.\n",
    "* ##### They provide information about the shapes and spatial relationships of objects within the image.\n",
    "* ##### The output of contour detection is a set of curves that represent the boundaries of objects or regions in the image.\n",
    "* ##### [Click to check the documentation](https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminated by user!\n"
     ]
    }
   ],
   "source": [
    "@error_handler\n",
    "def contours(path):\n",
    "    image = cv.imread(path)\n",
    "    image_copy = image\n",
    "    thresh = 100\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    gray = cv.cvtColor(image, cv.COLOR_RGB2GRAY)\n",
    "    while True:\n",
    "        _, binary = cv.threshold(gray, thresh, 255, cv.THRESH_BINARY)\n",
    "        cv.imshow('Gray Image', gray)\n",
    "        cv.imshow('Binary Image', binary)\n",
    "\n",
    "        contours, _ = cv.findContours(binary, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "        image_ = cv.drawContours(image, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "        cv.imshow(\"Input Image\", image_copy)\n",
    "        cv.imshow(\"Contour Detected Image\", image_)\n",
    "\n",
    "        show_text_window([f'Threshold: {thresh}'])\n",
    "\n",
    "        k = cv.waitKey(0)\n",
    "        uv, _ = get_updated_value(k, 25)\n",
    "        thresh += uv\n",
    "\n",
    "\n",
    "path = \"../Images/sudoku.jpg\"\n",
    "contours(path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 5, _Hough Space_:\n",
    "* ##### It's a mathematical concept to detect and represent geometric shapes, patterns, and features in an image.\n",
    "* ##### Hough Transform, a technique originally developed for line detection but later extended to detect other shapes such as circles and ellipses.\n",
    "* ##### Hough space plays a crucial role in finding and representing these shapes in a parametric form.\n",
    "* ##### [Click to check the documentation](https://docs.opencv.org/3.4/d9/db0/tutorial_hough_lines.html)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def circles(path):\n",
    "    image = cv.imread(path)\n",
    "    image = cv.medianBlur(image, 5)\n",
    "    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    circles = cv.HoughCircles(gray, cv.HOUGH_GRADIENT, 1, 20, param1=100, param2=25, minRadius=0, maxRadius=0)\n",
    "    circles = np.uint16(np.around(circles))\n",
    "\n",
    "    for circle in circles[0]:\n",
    "        *center, radius = circle\n",
    "        cv.circle(image, center, radius, (0, 255, 0), 2)\n",
    "        cv.circle(image, center, 2, (0, 0, 255), 3)\n",
    "        cv.imshow('Detected Circles', image)\n",
    "        cv.waitKey(0)\n",
    "\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "path = \"../Images/coins.jpg\"\n",
    "circles(path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## _The End_."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
